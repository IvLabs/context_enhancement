
train_translation.py --batch_size=32 --dfeedforward=1024 --epochs=32 --nhead=2 --nlayers=4
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'nhead' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'dfeedforward' was locked by 'sweep' (ignored update).
[34m[1mwandb[39m[22m: [33mWARNING[39m Config item 'nlayers' was locked by 'sweep' (ignored update).
Reusing dataset opus_rf (/home/ivlabs/.cache/huggingface/datasets/opus_rf/de-en/1.0.0/3725eb23f8df679ddd37d8d65a6bbfcda7732c66edccbc62a3c3b1354c934c9f)
Reusing dataset opus_rf (/home/ivlabs/.cache/huggingface/datasets/opus_rf/de-en/1.0.0/3725eb23f8df679ddd37d8d65a6bbfcda7732c66edccbc62a3c3b1354c934c9f)
Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
{"epoch": 0, "step": 0, "loss": 7.115720272064209, "time": 5}
/home/ivlabs/context_enhancement/context_new/context_enhancement/train_translation.py:264: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)
{"epoch": 0, "step": 5, "loss": 202.97476196289062, "time": 6}
translation model saved in checkpoint
{"epoch": 1, "step": 10, "loss": 151.204345703125, "time": 62}
translation model saved in checkpoint
{"epoch": 2, "step": 15, "loss": 76.84952545166016, "time": 83}
translation model saved in checkpoint
{"epoch": 3, "step": 20, "loss": 50.71405029296875, "time": 105}
translation model saved in checkpoint
{"epoch": 4, "step": 25, "loss": 38.18907165527344, "time": 127}
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 114, in message_loop
    msg = self._response_queue.get(timeout=1)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/multiprocessing/queues.py", line 108, in get
    res = self._recv_bytes()
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError
Exception in thread Thread-16:
Traceback (most recent call last):
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 198, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 743, in communicate_stop_status
    resp = self._communicate(req, timeout=timeout, local=True)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 545, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/home/ivlabs/miniconda3/envs/ectc/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 550, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
